{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"S9BJbEJ-yeON"},"outputs":[],"source":["# Step 1: Install Libraries\n","!pip install transformers datasets pandas torch sentencepiece -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qczWbl_BymCC"},"outputs":[],"source":["# Step 2: Import Libraries\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import MBartForConditionalGeneration, MBartTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IWCXTvp1yptd"},"outputs":[],"source":["# Step 3: Load the Dataset\n","file_path = \"/content/Bhagwad_Gita_QA_Pairs.xlsx\"  # Update with your file's path on Colab\n","df = pd.read_excel(file_path)\n","\n","# Assuming your dataset has columns: 'Question' and 'Answer' (English, Hindi, Sanskrit)\n","df = df.dropna()  # Remove rows with missing values\n","\n","# Example: Choose the Answer column for one language (e.g., Hindi)\n","language_code = \"hi_IN\"  # Options: 'hi_IN', 'sa' (for Sanskrit), 'en_XX'\n","df['Answer'] = df['Answer']  # Adjust as per your column names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5E-Dhw7yq-e"},"outputs":[],"source":["# Step 4: Prepare the Dataset\n","def preprocess_data(examples):\n","    model_inputs = tokenizer(examples['Question'], max_length=128, truncation=True, padding=\"max_length\")\n","    labels = tokenizer(examples['Answer'], max_length=128, truncation=True, padding=\"max_length\")\n","    model_inputs['labels'] = labels['input_ids']\n","    return model_inputs\n","\n","# Convert to Hugging Face Dataset format\n","dataset = Dataset.from_pandas(df)\n","tokenizer = MBartTokenizer.from_pretrained(\"facebook/mbart-large-50\", src_lang=\"en_XX\", tgt_lang=language_code)\n","\n","tokenized_dataset = dataset.map(preprocess_data, batched=True)\n","\n","# Split into train and validation datasets\n","train_test_split = tokenized_dataset.train_test_split(test_size=0.1)\n","train_dataset = train_test_split[\"train\"]\n","val_dataset = train_test_split[\"test\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B312aR8syuls"},"outputs":[],"source":["# Step 5: Load mBART-50 Model\n","model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6Zl3I44yyDS"},"outputs":[],"source":["\n","# Step 6: Define Training Arguments\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./mbart50-finetuned-bhagwadgita\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    predict_with_generate=True,\n","    logging_dir=\"./logs\",\n","    logging_steps=100,\n","    fp16=torch.cuda.is_available(),  # Enable mixed precision if GPU is available\n","    push_to_hub=False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNQj6loyyz5N"},"outputs":[],"source":["# Step 7: Define Trainer\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wCxI4Vyy1qM"},"outputs":[],"source":["\n","# Step 8: Train the Model\n","trainer.train()"]},{"cell_type":"code","source":["# Step 9: Save the Fine-tuned Model\n","trainer.save_model(\"./mbart50-finetuned-bhagwadgita\")\n","tokenizer.save_pretrained(\"./mbart50-finetuned-bhagwadgita\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7U9le6Ls1rgs","executionInfo":{"status":"ok","timestamp":1732563702353,"user_tz":-330,"elapsed":75579,"user":{"displayName":"Siddharth","userId":"00982699887461410866"}},"outputId":"d6843b81-fefe-4ab0-8bc3-2e77655d4196"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('./mbart50-finetuned-bhagwadgita/tokenizer_config.json',\n"," './mbart50-finetuned-bhagwadgita/special_tokens_map.json',\n"," './mbart50-finetuned-bhagwadgita/sentencepiece.bpe.model',\n"," './mbart50-finetuned-bhagwadgita/added_tokens.json')"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5bsSA-dUxx4l","executionInfo":{"status":"ok","timestamp":1732564795935,"user_tz":-330,"elapsed":36175,"user":{"displayName":"Siddharth","userId":"00982699887461410866"}},"outputId":"cd5759b9-5f56-400e-d3e1-f393265e2e8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Question: What is soul in hindi?\n","Answer: ।।11.20।। व्याख्या -- [इसी अध्यायके आरम्भमें अर्जुनने कहा था कि कामनाओंसे जिनका चित्त हर लिया गया है? ऐसे भक्तियोगी के बनो मत होना चाहिये। क्योंकि भगवान्के सिवाय दूसरी किसी वस्तुकी इच्छा नहीं है। इसलिये वह काम करना नहीं चाहता (टिप्पणी प0 597)। परन्तु जो भक्त मेरी ही उपासना करते हैं? उनके लिये मैं ही सर्वथा तत्पर रहता हूँ -- ऐसा कहते हैं।]यदा भूतपृथग्भावं ৷৷. मनःप्राणेन्द्रिय\n"]}],"source":["# Optional: Push to Hugging Face Hub\n","# trainer.push_to_hub(\"mbart50-finetuned-bhagwadgita\")\n","\n","# Step 10: Evaluate the Model with Enhanced Parameters\n","sample_question = \"What is soul in hindi?\"\n","\n","# Tokenize the input question\n","inputs = tokenizer(\n","    sample_question,\n","    return_tensors=\"pt\",\n","    max_length=256,  # Allow for a longer input\n","    truncation=True\n",").to(model.device)\n","\n","# Generate the answer with custom parameters\n","output_tokens = model.generate(\n","    **inputs,\n","    max_length=1000,  # Maximum length of the generated output\n","    num_beams=3,     # Use beam search for better coherence\n","    no_repeat_ngram_size=2,  # Avoid repeating n-grams\n","    early_stopping=True,  # Stop when a complete sentence is formed\n","    length_penalty=1.0  # Adjust length bias (higher value favors longer outputs)\n",")\n","\n","# Decode the generated answer\n","decoded_answer = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n","\n","# Print the results\n","print(f\"Question: {sample_question}\")\n","print(f\"Answer: {decoded_answer}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyM+7aGbp9FpEQS+QpM8Y+kL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}